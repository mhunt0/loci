%Time-stamp: <2002-09-06 12:21:41 peo>
\documentclass[10pt,epsf]{book}
\renewcommand\familydefault{ptm}
\DeclareMathAlphabet{\mathmyrm}{OT1}{ptm}{m}{n}
\DeclareMathAlphabet{\mathmybf}{OT1}{ptm}{bx}{n}
\SetMathAlphabet{\mathmyrm}{bold}{OT1}{ptm}{bx}{n}
\setlength{\textheight}{7.75in}
\setlength{\textwidth}{5.7in}
\setlength{\parskip}{3mm}
\setlength{\parindent}{0.0in}
\setlength{\topmargin}{5mm}
%\setlength{\bottommargin}{5mm}
\setlength{\headheight}{5mm}
\setlength{\headsep}{5mm}
\setlength{\oddsidemargin}{2cm}
\setlength{\evensidemargin}{2cm}
\unitlength=1in
\title { Loci : A Tutorial }

\usepackage{epsf}    % used for importing encapsulated postscript figures
\usepackage{amsmath} % used for extended formula formatting tools
\usepackage{amssymb}
\usepackage{theorem}
\usepackage{euscript}

%\includeonly{intro}

\begin{document}
%\small
\tableofcontents
%\listoffigures
\maketitle
\thispagestyle{empty}
\newpage
\setcounter{page}{1}

\include{intro}
\include{lfvm}

\chapter{ Basic Concepts }
\section{Notation used in this document}
In this document we use the {\tt typewriter} font to distinguish
actual Loci programming keywords, classes, and data-structures.
\section{ Installing Loci}
After you untar Loci you will have a directory structure like so:

\begin{verbatim}
Loci/
Loci/src
Loci/Tutorial
\end{verbatim}

To install Loci, you need to use {\tt tmpcopy} to make a linked copy
of the source code (usually to the {\tt /usr/tmp} directory).  You
can use environment variables to change how the tmpcopy routine works.
For example, you can set the target directory (where you will be
compiling the Loci libraries), and the compiler.  For example, to set
the target directory to {\tt /home/test/OBJ} and the compiler to {\tt
  gcc3.0}, enter (NOTE: Run tmpcopy from the Loci directory!):

\begin{verbatim}
LOCI_TARGET=/home/test/OBJ LOCI_COMP=gcc3.0 ./tmpcopy
\end{verbatim}

The possible compilers that will work with Loci are:  

\begin{center}
\begin{tabular}{|l|l|}
\hline
{\tt LOCI\_COMP} & Description \\
\hline
\hline
{\tt KCC }      & Kuck and Associates C++ compiler \\
{\tt gcc }      & gcc 2.95.3 \\
{\tt gcc3.0}    & gcc 3.0.3 \\
{\tt CC\_sgi}    & SGI's CC compiler \\
\hline
\end{tabular}
\end{center}

Once you have run the {\tt tmpcopy} command, you probably should
inspect the {\tt comp.conf} and {\tt sys.conf} files in the target directory.
The {\tt comp.conf} file configures for the particular compiler that you
have selected.  You should check that the path to the compiler is
correct.  The {\tt sys.conf} file configures the particulars of any
given system.  You will need to make sure that the paths to libraries
are correct and that the installation directory ({\tt INSTALL\_DIR})
points to the location where you want to install.  To install Loci
simply type:

\begin{verbatim}
make
make install
\end{verbatim}


\section{ Compiling Loci Programs }

The most direct way to compile Loci programs is to use the Makefile
template provided in this tutorial.  It is usually as simple as
including the Loci.conf file that comes as part of your Loci
installation.  See the following makefile for an example.

\include{Makefile_ex}

\section{Loci Initialization}

Before any of the main Loci functionality can be used (that is the
components that follow this section), Loci must be initialized.  Loci
has an initialize function that must be called before executing Loci
functionality and a finalize method that must be called just before
exiting the program.  For example, see below:

\begin{verbatim}
#include <Loci.h>

int main(int argc, char *argv[]) {
   // Initialize Loci
   Loci::Init(&argc, &argv) ;

   // ...
   // Loci Program
   // ...

   // Before exiting, call finalize to let Loci clean up.
   Loci::Finalize() ;
   return 0 ;
}
\end{verbatim}



\section{Running an Example}

Most of the computations discussed in this document are part of an example
Loci implementation of the finite-volume method applied to the
two-dimensional heat conduction problem.  You will find this code
under the {\tt lfvm} directory provided with the tutorial.  If you
compile the {\tt lfvm} tutorial you will be able to run example
queries to see the computations proceed for the rule we have just
described above.  We can run the above program by executing {\tt lfvm}
with the flag {\tt -q area} to query for area.  The resulting query
produces output such as:

\begin{verbatim}
% ./lfvm -q area example_grid
reading grid file example_grid
node_alloc = ([0,24])
triangle_alloc = ([25,60])
constraint = BC_bottom nodes = ([0,3])
constraint = BC_left nodes = ([0,0][7,7][14,14][21,21])
constraint = BC_top nodes = ([21,24])
constraint = BC_right nodes = ([3,3][10,10][17,17][24,24])
found 48 internal edges, 12 on boundary
max_iteration=10000
heat flux boundary nodes = ([21,24])
temperature prescribed boundary nodes = ([0,3][7,7][10,10][14,14][17,17][21,21][24,24])
generating dependency graph...
Adding rule gradDotN(T)<-(cl,cr)->(centroid,T)
setting up variable types...
decomposing graph...
existential analysis...
creating execution schedule...
area = 
{([25,60])
0.25
....
\end{verbatim}

We can see the execution schedule produced by the Loci query by
examining the file {\tt ./schedule} provided by the {\tt lfvm} example
program.  For example:

\begin{verbatim}
% more .schedule
allocate all variables
create 1 threads
thread barrier ()

area<-triangle_nodes->pos  over sequence ([25,60])
thread barrier area

destroy threads
\end{verbatim}

As we can see, the schedule is simple:  we have called the compute
method for our area rule and passed it a sequence that includes all
triangles in our grid.




\section{Entities, Sets, and Sequences}

In Loci, computations are represented by associating (binding) values
(attributes) to entities.  Although entities can be considered in
rather abstract terms, in Loci we often will often interchange the
meaning of entity with the integer identifier that is used to label a
given entity.  Thus we may talk of entity $1$ when we are really
referring to the entity labeled $1$.  (Do not count on this remaining
true indefinitely.  We plan to change Loci to make entities
first-class objects.) 

It is useful to consider groups of entities that have similar
attributes.  In Loci we have two data structures for representing sets
of entities:  1) the {\tt interval} and 2) the {\tt entitySet}.  For
example, if we wish to represent the entities labeled from $1$ to
$100$ we would use the Loci class {\tt interval(1,100)}.  On the other
hand, the {\tt entitySet} can be used to represent arbitrary
collections of entities.  Once we have described a collection of
entities using the {\tt entitySet} class we can also create new sets
of entities using unions, intersections, and other useful set
operations.  

The {\tt entitySet} class provides a true set semantics.
That is, ordering of insertion is not preserved and there is no
duplication.  Either an entity is in the set or it is not.  If we need
to preserve the order of entities for looping or other control then we
use the {\tt sequence } class.  The {\tt sequence} class provides
operations for concatenation and reversal and can be thought
of as a list of entity labels.  It should be noted that users
generally don't create sequences in Loci, but rather the scheduler
generates sequence of entities for computations.  However, if there is
ever a need to keep track of a particular ordering of entities, then
sequences are the data-structure that accomplishes this task.

The following program segment (included with the tutorial programs)
provides examples of how to create and use the {\tt  entitySet} and
{\tt sequence} classes.  This provides examples of the most commonly
used programming techniques for these classes.

\include{entities_cc}

\section{Loci Containers}

In Loci, containers are entity based.  That is, a container provides
an association between entities and values.  There are two basic types
of containers, parameters and stores.

Parameters provide a way of associating a single value with a set of
entities.  With respect to the set of entities that they are associated
with, parameter variables behave much like global variables.  There are
two parameter containers: param and blackbox, which differ in their
scope and intended usage.  The param variables are synchronized over all
of the processors and can only be used with first class objects that Loci
knows about.  The blackbox variables are not synchronized over processors
and can hold any data type.  Blackbox containers are intended to be used
to hold data structures for third party libraries, or other data types
that Loci is not able to manage directly.

Stores provide a one-to-one correspondence between entities and values.
In shorter terms, stores look like very flexible arrays.  The stores
come in a variety of forms that allow various types of run-time selection
of the sizes of the types they contain.  For example, the storeVec
provides a store that contains vectors whose size isn't specified until
run time.

Perhaps the fastest way to learn how to apply Loci containers is to see
them in action.  The following is a short program that illustrates the
syntax of Loci containers and some basic examples of their application.

\include{containers_cc}

\section{Loci Relations}
In addition to containers, Loci provides ways of describing
relationships between entities.  The simplest of these relationships
is the constraint.  The constraint simply identifies a grouping of
entities and is used to assign attributes to entities.  For example,
a boundary condition may be specified by placing those entities in the
boundary in a boundary constraint.  The most basic of the relations is
the Map.  This provides a means of describing the relationship between
entities.  Maps are used to describe the data-structures typically
encountered in unstructured mesh computations and come in a variety of
forms in Loci.  The basic {\tt Map} class provides a one-by-one
correspondence whereas the {\tt MapVec} templated class provides a
one-to-many correspondence.  Similarly, the {\tt multiMap} class
provides the most generic interface where each entity may have 0 or
more other entities related to it.  The following source code
demonstrates the basic user interface for the Map family of classes.


\include{relations_cc}



\chapter{Representing and Manipulating Data Structures}
\section{Creating Data Structures in Loci}

In Loci, data structures are represented as relations between entities
using Maps.  These data structures, and associated initial values, are
stored in a repository called the fact database which is managed by
the {\tt fact\_db} class.  The fact database is what Loci uses to
coordinate values between computations.  All Loci containers, (e.g.
store, Map, etc.) can be registered into the fact database.

For example, we create a fact database that contains the fact ``value'' using the {\tt create\_fact} member function as follows:
\begin{verbatim}
      // Create a Fact Database
      fact_db facts ;

      // Create a new value
      store<double> value ;
      // ...
      // ... Read In Values
      // ...
   
      // Insert value into the fact database
      facts.create_fact("value",value) ;
\end{verbatim}

Once containers are registered in the fact database, we can later
extract the values that were placed in the fact database using the 
{\tt get\_fact} member function.  For example, we can obtain the
current values from the fact database as follows:
\begin{verbatim}
      store<double> value(facts.get_fact("value")) ;
\end{verbatim}

Also if we wish to allocate new entities, we can ask the fact database
for a new allocation by calling the method {\tt get\_allocation} with
an argument of the number of entities that you need allocated.  For
example:
\begin{verbatim}
      entitySet node_entities = facts.get_allocation(number_of_nodes) ;
\end{verbatim}

For a more detailed example, refer to the subroutine listed below
which reads in a file that defines a triangulated mesh.  The mesh file
consists of a list of points in 2-D space and a list of triangles that
are formed using those points.  This file reader installs the node
positions and the triangle definitions in the fact database passed
into its argument list.  The mesh is defined by two Loci containers.
One is a {\tt store} that contains 2-D vectors named ``pos'' that
defines the nodal positions and a {\tt MapVec} named
``triangle\_nodes'' that defines the three nodes that form a triangle
in a counter-clockwise ordering.

\include{grid_reader_cc}

\section{Transforming Data structures in Loci}

We may need to transform data structures from one form to another
before they are useful for computations.  For example, if we are
to use the mesh of triangles read in the previous section in a
finite-volume based algorithm, we would usually need an edge-centric
data structure rather than a cell-centric data structure that the
triangle definition provides.  So, we would like to convert this
triangle based data structure to one that consists of edges.  Each
edge is defined by two nodes and two cells on either side.  Boundary
edges will be require special treatment since there is no outer
triangle.  We will create a ``ghost'' cell in these cases to make the
data structure consistent for all edges.  Also, we will want to make
sure that each edge is represented in this data structure only once.

We create this edge-based data structure by looping over the three
edges of each triangle, and by searching neighboring triangles to find a
triangle that shares the same edge.  Once we find this triangle, then
we know the two nodes and two cells that form an edge.  In order to
make sure that we don't find the same edge twice, we mark triangles
that we visit and only insert the edge we find when none of the
triangles have been visited before.  If we can't find a matching
triangle, then we know the edge must be a boundary edge that requires
a ghost cell allocation.

In order to search only the neighboring triangles, we need to
transpose the ``triangle\_nodes'' in order to obtain a mapping from
nodes to the triangles that are defined using that node.  A transpose
of a map is found using the {\tt inverseMap} function.  This function has
four arguments.  The first is a {\tt multiMap} that is returned by the
function.  The second is the {\tt Map} that will be transposed.
Following this are the entities for which the transposed map will be
defined (in this case it will be all the nodes in the problem).  The
final argument is the entities that describe the region of the map
that will be transposed.  In this case, we are interested in
transposing the {\tt triangle\_node} map for all triangles.  Therefore
to get the map from nodes to all neighboring triangles we execute the
function 
\begin{verbatim}
  Loci::inverseMap(nodes2tri,triangle_nodes,node_set,triangle_set) ;
\end{verbatim}

Once we have the map from nodes to triangles, we can choose one of the
nodes of an edge to search for the triangle that contains the same
edge.  Once we have set up the preliminaries, we use a vector to store
each edge as we find it.  Once we know how many edges are in the mesh,
we can allocate entities for the edges and create the maps
representing the edge data structure.  For this we create three maps,
``cl'', ``cr'', and ``edge\_nodes'' representing the left and right
cells and the two nodes that define the edge.  The following code
shows how to set up these data structures using Loci.

\include{setup_edges_cc}

\chapter{Computational Rule Specification}

In Loci, computations are performed by executing rules.  At a high
level, it is useful to think of Loci as a ``make'' program for
managing simulation computations instead of compilations.  A Loci rule
includes a documentation section that describes the values that it
depends upon and the values that it produces, combined with a
computation method that can perform the documented computation when
needed.  The following sections will describe how to perform various
types of computations using Loci rules.

\section{Rule Signatures}

Before we begin describing Loci rules, we should first describe how we
name Loci rules.  Rule signatures are the names of Loci rules.  Loci
will only allow one computation of a given rule signature, so we can
use rule signatures to identify any given computational component in a
Loci program.  The simplest rule signature just shows outputs of the
rule followed by the inputs.  The inputs and outputs are divided by
the ``{\tt <- }'' symbol.  For example, a rule that inputs values {\tt
  A} and {\tt B} to produce output {\tt C} has a rule signature as
follows:

\begin{verbatim}
C<-A,B
\end{verbatim}

If relations (such as the {\tt Map} {\tt cl}
and the {\tt Map} {\tt cr} in the edge-based data structure of the
previous section) are used in a computation, then they are included 
in the rule signature.
For example, a computation that computes a value {\tt D }
by averaging value {\tt C } on both sides of any given face would
be documented by the rule signature:

\begin{verbatim}
D<-(cl,cr)->C
\end{verbatim}

What this rule signature means is that {\tt D } is computed by
accessing {\tt C } through the relations identified as 
{\tt cl } and {\tt cr }.  Note that in these rule signatures, 
the comma binds more weakly than
the mapping right arrow operator.  The
parentheses, therefore, are required.

\section{Rule Databases}

Rules are managed through the use of a rule database class called
``{\tt rule\_db }''.  Generally users put rules in the rule database
from the {\tt global\_rule\_list }, a list of rules that is created
before {\tt main} is called by {\tt register\_rule } templates.  As a
result, the usual way that a rule database is manipulated in Loci is
to insert all of the rules in the global rule list.  This is
accomplished with the following code segment: 

\begin{verbatim}
  ////////////////////////////////////////////////////////////////////
  // rule_db and global_rule_list are defined in Loci.h
  ////////////////////////////////////////////////////////////////////
  // Create a rule database called rdb
  rule_db rdb ;

  ////////////////////////////////////////////////////////////////////
  // Add all of the rules that were inserted into the global_rule_list
  // by register_rule<> types into the rule database rdb
  ////////////////////////////////////////////////////////////////////
  rdb.add_rules(global_rule_list) ;
\end{verbatim}

\section{Creating an execution schedule}

Once we have a database of facts and a database of computational
rules, Loci can use these databases to satisfy queries.  We obtain an
execution schedule that can compute these results using the function
{\tt create\_execution\_schedule} provided by Loci.  This function
takes three arguments, 1) the rule database of computations to use for
this query, 2) the fact database of data structures and initial
values, and 3) a C++ string that contains the variable name that we
wish to query for.  This function returns an {\tt executeP} which is a
pointer to the execution schedule.  {\tt executeP} is a counted
pointer that will automatically delete the memory allocated to the
schedule when the object is destructed.  If a schedule could not be
determined, {\tt create\_execution\_schedule} returns a null pointer.  

We can then execute the schedule by calling the execute member
function of the execution schedule, as in
\begin{verbatim}
  schedule->execute(facts) ;
\end{verbatim}

As an additional detail, if we wish to execute on a distributed memory
machine, we must first distribute the fact database across processors
before beginning the scheduling.  This is accomplished using the {\tt
  generate\_distribution} and {\tt distribute\_facts} functions
provided by Loci.  See the below code segment for a more complete
example.

\begin{verbatim}
  ////////////////////////////////////////////////////////////////////
  // Here we distribute the fact database, if we are running on
  // multiple processors.  If we are running serially then these
  // operations have no effect.
  // First we obtain a partition of entities based on the current
  // rules and facts
  ////////////////////////////////////////////////////////////////////
  std::vector<entitySet> partition = Loci::generate_distribution(facts,rdb) ;
  ////////////////////////////////////////////////////////////////////
  // Now we use this distribution to partition the facts to processors.
  // The assumption at this point is that every processor has 
  // identical facts and rdb.
  ////////////////////////////////////////////////////////////////////
  Loci::distribute_facts(partition, facts, rdb) ;

  ////////////////////////////////////////////////////////////////////
  // Here we ask Loci to create an execution schedule that will use
  // the rules in the rule database ``rdb'' and the data in the
  // fact database ``facts'' to obtain the variable(s) specified in
  // query.  Here query is a c++ string that contains the name of
  // the variable that we are querying for (or a comma separated
  // list if we wish to query for more than one variable).
  ////////////////////////////////////////////////////////////////////
  executeP schedule = create_execution_schedule(rdb,facts,query) ;

  ////////////////////////////////////////////////////////////////////
  // If Loci is unable to derive an execution schedule it will return
  // a null pointer.
  if(schedule == 0) {
    // Output a diagnostic if no schedule can be obtained
    cerr << "unable to produce execution schedule to satisfy query for "
         << query << endl ;
  } else {
    //////////////////////////////////////////////////////////////////
    // here we actually execute the computation schedule.  The
    // result will be placed into the fact database ``facts'' for
    // later extraction.
    //////////////////////////////////////////////////////////////////
    schedule->execute(facts) ;

    //////////////////////////////////////////////////////////////////
    // Here the execution is complete and the requested computations
    // are in facts.
  }
\end{verbatim}




\section{Pointwise Computations}

A rule is implemented as a class that provides a constructor that
documents the inputs and outputs to the computation and a virtual
compute method that provides computations for arbitrary collections of
entities.  The most fundamental of these computations is the pointwise
rule.  The pointwise rule represents a computation that can be applied
individually, entity by entity.  For example, consider the case of
computing the area of each triangle in the triangular mesh described
earlier.  In order to compute the area of any given triangle we need
to access the positions of the triangle's three nodes.  These node
positions can be accessed using the {\tt triangle\_nodes} map.  The
areas of all of the triangles in the mesh can be computed by looping
over all entities that have the {\tt triangle\_nodes} defined.  More
precisely, not only must {\tt triangle\_nodes} be defined, but the
entities that this map refers to must also have the attribute {\tt
  pos}.  This set of entities is called the context of the rule and
represents the possible entities over which the computational
subroutine may be called.  A rule that computed areas in such a
fashion would have a rule signature of
\begin{verbatim}
area<-triangle_nodes->pos
\end{verbatim}
where area would be the attribute that this computational routine
would provide when the inputs are provided.  

In order to define a pointwise rule, the user defines a class that
inherits from the class {\tt pointwise\_rule} that is provided in {\tt
  Loci.h}.  This class will contain the {\tt store}, {\tt Map}, and
{\tt param} containers that will be used for the computations.  Input
containers should use the {\tt const\_} prefix which establishes that
the container can only be accessed in a read-only mode.  The
constructor of the rule is responsible for registering the containers
used in the computations and documenting the inputs and outputs of the
rule.  The containers are registered using the rule member function
{\tt name\_store()}.  This function attaches a symbolic name (string)
to the containers so that they can be attached to containers stored in
any given fact database when an execution schedule is formed.
Additionally, {\tt input} and {\tt output} methods are provided to
document both input and output data of the given computation
encapsulated by the rule.  Below, a simple example shows how to create
a pointwise rule to compute areas and centroids of triangles in the
triangular mesh.


\include{cell_props_cc}

\section{Reduction Computations}

There is an alternative approach that we could have taken in the
computation of areas.  Instead of looping over triangles, instead we
could have looped over edges and computed the area contribution
associated with each edge as illustrated in figure \ref{fig:area}.  We
define the edge area contribution as the area of the triangle formed
by the two edge nodes and the centroid of the cell.  Obviously the
triangle area is equal to the sum of all of the edge area
contributions.  This computation method has the advantage that it can
be made to compute the area of any general polygon, whereas the
previous approach was limited only to triangles.  Also, since a
natural way of expressing this computation is to loop over edges
(which is typically what is required in finite-volume computations) we
may be able to dispense with storing the relation {\tt
  triangle\_nodes} all together.  However, if we wish to define this
computation via iteration over edges, we will need to sum up the
results incrementally.  As a result we won't be able to express this
computation as a pointwise rule since the computation of area does not
occur completely point by point, but instead is spread out over
several edge updates.

For this style of computation we need to describe a reduction.  In
Loci we describe a reduction through the use of {\tt unit\_rule} and
{\tt apply\_rule}.  The {\tt unit\_rule} defines the identity of the
operator over which we are doing the reduction, while a set of {\tt
  apply\_rule}s define the summing update that we perform as we are
adding each edges contribution to its neighboring triangles.
Following is an example program that shows how to compute areas using
this edge-centric approach.

\begin{figure}[h]
\centerline{
\epsfxsize=3.2in
\epsfbox{figures/edge_area.eps}}
\caption{Computing Triangle Area by Accumulating Edge Contributions}
\label{fig:area}
\end{figure}

Note that reductions can also be used to compute parameter values.
The specification of the reduction is the same as when the output is
a store, and the resulting parameter is the reduced (accumulated)
value.  In fact, an {\tt apply\_rule} is the only valid rule for
computing parameters from stores.  See the file {\tt stable.cc} in the
finite-volume example for an illustration of how to specify reductions
for computing parameters.

\include{area_reduce_cc}

\section{Singleton Rules and Parameter Computations}

Singleton rules are defined for computations that are performed
exclusively on parameters.  Since these computations are on single
values that are associated with a group of entities, it is not
necessary to perform any loops.  However the attribute that is
computed as a result of the rule is only associated with the entities
that are in the intersection of the entities given the attributes of
all of the inputs.  (Note:  In the parallel implementation, all
parameters are duplicated on each processor, so these singleton rules
are computed on each processor when parallel processing is used [no
communication is invoked].)

\begin{verbatim}
//////////////////////////////////////////////////////////////////////////////
//
//
//  Here we compute a new parameter C by multiplying the values contained in
//  parameters A and B.
//  
//  We define a singleton rule by creating a class that inherits from 
//  the class singleton_rule.
class singleton_example : public singleton_rule {
// Here we define the paramters involved in the computations.
// ** Note, only parameters allowed in singleton computations!
  const_param<double> A ;
  const_param<double> B ;
  param<double> C ;
public:
// Here we provide a constructor that names stores and specifies inputs and
// outputs as before.
  collapse_info() {
    name_store("A",A) ;
    name_store("B",B) ;
    name_store("C",C) ;
    input("A,B") ;
    output("C") ;
  }

  virtual void compute(const sequence &seq) {
// Now in the compute method, we don't loop since we only have a single
// value representing the entire set of entities.  Instead we use the
// dereference operator (*) to access the values.
    *C = (*A)*(*B) ;
  }
} ;

// Now we can register this rule like any other Loci Rule
register_rule<singleton_example> register_singleton_example ;
\end{verbatim}

\section{Iterative Computations}


Iteration is defined by way of three types of rule specifications:
build rules that construct the iteration, advance rules that advance
the iteration, and collapse rules that terminate the iteration.  This
specification follows an analogy to the inductive proof in that build
rules are analogous to an inductive base while advance rules are
analogous to an inductive hypothesis.


Iterations are specified by adding an iteration label to variable
identifiers.  Iteration labels are organized into a hierarchy that is
rooted at stationary time (values that don't iterate).  It is assumed
that computations can proceed at any given iteration level while
accessing values computed at either its iteration level or at parent
levels in the label hierarchy.  The iteration label is just a list of
iterator variables that follows the variable name enclosed in braces.
For example, to access value {\tt v} for iteration {\tt n} we have 
{\tt v\{n\}}.  This relationship between traditional imperative
languages' 
loop nesting and the iteration label hierarchy is shown in figure
\ref{fig:nested}. 

\begin{figure}[h]
\centerline{
\epsfxsize=3.4in
\epsfbox{figures/nested.eps}}
\caption{Nested Loops are characterized by a hierarchy of iteration labels}
\label{fig:nested}
\end{figure}

For example, an iteration where a variable named {\tt q} is iterated
to a converged solution may be described by the following three rules:
1) a build rule of the form {\tt q\{n=0\}<-initial\_condition}, 2) an
advance rule similar to {\tt q\{n+1\}<-q\{n\},delta\_q\{n\}}, and 3)
an iteration collapse rule {\tt
  solution<-q\{n\},CONDITION(converged\{n\})}.  Iteration in this
example proceeds by initializing the first iteration, {\tt q\{n=0\}},
using the build rule.  Next, termination of iteration is checked
by computing {\tt converged}.  If the test succeeds then the collapse
rule terminates the iteration.  Finally the iteration advances in time
by the repeated application of the advance rule which computes values
for {\tt q} for the next iteration ({\tt\{n+1\}}) given current
iteration values at time level {\tt\{n\}}.  Note that the completion
of these rules may require invoking other rules specified in the rule
database.  In this case, rules that compute {\tt converged\{n\}} and
{\tt dq\{n\}} will also need to be scheduled.

To support iteration, variables that exist in lower levels of the
iteration hierarchy are automatically promoted up the iteration
hierarchy.  Thus a variable that is computed in iteration {\tt\{n\}}
is communicated to iteration {\tt\{n,it\}} automatically.  In
addition, rules that are specified completely at the stationary level
will be promoted to any level of the hierarchy.  This allows for the
specification of relations that are iteration independent (for
example, $p = \rho \tilde{R} T$ implies $p^n = \rho^n \tilde{R}^n
T^n$).


\include{integration_cc}

\section{Parametric Rules}

We can also create generic, or parametric rules.  These can be any
type of rule and allows Loci to create new rules by variable
substitution.  The output of a parametric rule includes variable names
that are followed by parenthesis enclosed parameter lists.  When these
parameters occur in the inputs to the rule, they will be substituted
by the provided parameter.  See the gradient routine that follows for
an example of how to develop and use parametric rules.

\include{gradient_cc}

%\include {dbase}
%\include {example}
%\include {make}
%\include {appendix}

%\appendix{datatype}
\include {datatype}
%\appendix{io}
\include {io}

\chapter{Loci Helper Classes}
\section{Loci Helper Classes}

Loci also provides a few helper classes that are often useful in
numerical computations.  
One is the {\tt Array} template class which provides a
mechanism for creating Arrays as first class objects that are
appropriate for using as classes used in templated containers. ({\it
Never use C arrays in templated containers.  Their semantics are
different from other C++ objects and may break templated code in
unexpected ways.})  In addition to the {\tt Array} template class,
classes for three and two dimensional vectors are also provided.  See
the following example code to see how to use these helper classes.

\include{helpers_cc}

\include{third_party}

\end{document}

