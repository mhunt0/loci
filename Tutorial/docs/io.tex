\chapter{Input and Output}
%\appendix {Input Output}
Loci used HDF5 (Hierarchical Data Format)  to read-write data from its 
containers. All the containers of Loci has the following member
virtual functions. 
%
\begin{itemize} 
\item virtual void readhdf5(hid\_t group\_id, hid\_t dataspace, hid\_t
  dataset, hsize\_t dimension, const char* name, frame\_info \& fi,
  entitySet \&  eset); 
\item virtual void writehdf5(hid\_t group\_id, hid\_t dataspace,
  hid\_t dataset, hsize\_t dimension, const char* name, entitySet \&
  eset) const ; 
\end{itemize}

%
In order to hide a lot of the implementation details from the user, a
much simpler interface is provided.
\begin{itemize} 
\item void read\_container(hid\_t group\_id, const char* name,  storeRepP qrep)
\item void write\_container(hid\_t group\_id, const char* name,  storeRepP qrep)
\end{itemize}

%
The name of the variable and a {\tt storeRepP} of the container is
passed along with the group\_id to the routines. The routines are
designed to work in a scalable fashion for distributed memory systems. 
{\tt group\_id} is the valid HDF5 group in which data is written. {\tt eset} is
the entitySet for which data is written. One simple example of
creating a group is given below. 
%
\begin{verbatim} 
hid_t file_id  = H5Fopen(filename, H5F_ACC_RDONLY, H5P_DEFAULT);
hid_t group_id = H5Gopen(file_id, groupname.c_str() );
\end{verbatim} 

%
\par Now we shall give three examples for writing facts
\begin{itemize}
\item  In the first example, we shall write facts with atomic datatype, which
are predefined in Loci. Using these datatype doesn't require anything extra 
from the user.
\item In the second example, we will write compound datatype, in which user
specify {\em Identity Converters} and insert them into Loci datatype. Once the
new datatype is build, using is as simple as example one.
\item In the third example, we will write class which uses {\em user
    defined conversion} 
\end{itemize}
\section { Writing atomic datatype }
In the following example, we shall use {\tt store} container and fill it with
some data. We will demonstrate how the facts database is called to write the
contains of the container in HDF5 data format.
\begin{verbatim}
#include <Loci.h>
using namespace std;

store<int> store_int ;   // Container with integer datatype
entitySet eset;   // EntitySet

//*******************************************************************
// Create a fact, fill it with some data and register it with facts
// database
//*******************************************************************
void GenerateData()
{
  int num = 10;
  eset = interval(1,num);
  store_int.allocate(eset);
  for( int j = 1; j <= num; j++) 
    store_int[j] =   100+j;
}
//*******************************************************************

int main(int argc, char *argv[])
{
  Loci::Init(&argc, &argv) ;
  GenerateData();
  hid_t file_id  = H5Fcreate("example", H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);
  hid_t group_id = H5Gcreate(file_id, "store_int", 0) ;
  Loci::write_container(group_id, store_int.Rep()) ; 
  H5Gclose(group_id) ;
  H5Fclose(file_id) ;
  Loci::Finalize() ;
}
//*******************************************************************
\end{verbatim}
The execution of the above program will produce {\tt example.hdf5} file. 
\begin{verbatim}
 HDF5 "example" {
GROUP "/" {
   GROUP "store_int" {
      DATASET "Interval Set" {
         DATATYPE  H5T_STD_I32LE  
         DATASPACE  SIMPLE { ( 2 ) / ( 2 ) } 
         DATA {
            1, 10
         } 
      } 
      DATASET "data" {
         DATATYPE  H5T_STD_I32LE  
         DATASPACE  SIMPLE { ( 10 ) / ( 10 ) } 
         DATA {
            101, 102, 103, 104, 105, 106, 107, 108, 109, 110
         } 
      } 
      DATASET "is_stat" {
         DATATYPE  H5T_STD_I32LE  
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) } 
         DATA {
            0
         } 
      } 
      DATASET "vec_size" {
         DATATYPE  H5T_STD_I32LE  
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) } 
         DATA {
            1
         } 
      } 
   } 
} 
} 


\end{verbatim}
\par Notice the output, HDF5 write all necessary information about the
container. EntitySet is written under the {\em Interval Set} dataset
and the data is written under {\tt store\_int} dataset. The {\tt
  is\_stat } dataset tells whether the container has atomic type or
user defined type. A value of 0 indicates that the container has atomic 
type data and a value of 1 indicates that the container contains user
defined type. Another dataset that gets written out is the {\tt
  vec\_size}. This is used as an indication to distinguish between
{\tt stores}, {\tt storeVecs} and {\tt multiStores}. In the above
example, since the container is a {\tt store}, the {\tt vec\_size} is
1. Each datatype and dataspace is also specified in the file. {\tt
  H5T\_STD\_I32BE} tells us that data was 32 bit, and big-endian
integer data.   
%

\section {Distributed facts }
\begin{verbatim} 
  #include <Loci.h>
using namespace std;

namespace Loci {
  struct My_Type {
    list<int>  alist;
    friend ostream& operator << (ostream &, const My_Type &);
    friend istream& operator >> (istream &, My_Type &);
  };
  
  //*******************************************************************
  inline std::ostream& operator << ( std::ostream &s, const My_Type &obj)
  {
    list<int> :: const_iterator ci;
    list<int> :: const_iterator begin = obj.alist.begin();
    list<int> :: const_iterator end   = obj.alist.end();
    for( ci = begin; ci != end; ++ci)
      s << *ci <<" ";
    return s;
  }
  //*******************************************************************
  inline std::istream& operator >> ( std::istream &s, My_Type &obj)
  {
    obj.alist.clear();
    int newval;
    s >> newval;
    obj.alist.push_back( newval );
    return s;
  }
  //*******************************************************************
  class My_Type_SchemaConverter;
  
  template <>
  struct data_schema_traits<My_Type> {
    typedef USER_DEFINED_CONVERTER Schema_Converter ;
    typedef int Converter_Base_Type ;
    typedef My_Type_SchemaConverter Converter_Type ;
  };
  
  class My_Type_SchemaConverter {
    // For the schema converter, we always store a reference to the object
    // we are converting schmata for.
    My_Type &RefObj ;
  public:
    explicit My_Type_SchemaConverter(My_Type &new_obj): RefObj(new_obj) {}
    int getSize() const {
      return RefObj.alist.size() ;
    }
    void getState(int *buf, int &size) {
      size = getSize() ;
      int ii=0;
      
      list<int> :: const_iterator ci;
      list<int> :: const_iterator begin = RefObj.alist.begin();
      list<int> :: const_iterator end   = RefObj.alist.end();
      for(ci = begin; ci != end; ++ci)  {
        buf[ii++] = *ci;
      }
    }
    void setState(int *buf, int size) {
      RefObj.alist.clear();
      for(int i=0;i<size;++i)
        RefObj.alist.push_back(buf[i]);
    }
  };
}

multiStore<Loci::My_Type> data ;   // Container
store<int> cnt ;
int num = 10 ;
entitySet eset  = interval(1, num) ;   // EntitySet
void GenerateData()
{
  cnt.allocate(eset) ;
  for(entitySet::const_iterator ei = eset.begin(); ei != eset.end(); ++ei)
    cnt[*ei] = *ei ;
  data.allocate(cnt) ;
    for(entitySet::const_iterator ei = eset.begin(); ei != eset.end(); ++ei) {
    int indx = 1;
    for(int i = 0; i < cnt[*ei]; ++i)
      for(int j = 0; j < 3; j++) {
        data[*ei][i].alist.push_back(indx);
        indx++;
      }
    indx = 1;
    ++ei ;
    for(int i = 0; i < cnt[*ei]; ++i)
      for(int j = 0; j < 5; j++) {
        data[*ei][i].alist.push_back(indx+100);
        indx++;
      }
      }
}
int main(int argc, char *argv[])
{ 
  Loci::Init(&argc, &argv) ;
  fact_db facts ;
  rule_db rdb ;
  dMap remap ;
  std::vector<entitySet> partition(Loci::MPI_processes) ;
  GenerateData();
  facts.create_fact("multiStore", data) ;
  Loci::storeRepP reorder_data ;
  if(Loci::MPI_processes > 1) {
    partition = Loci::generate_scalable_distribution(facts, rdb, Loci::MPI_processes) ;
    Loci::distribute_facts(partition, facts, rdb) ;
  }
  Loci::storeRepP new_sp ;
  new_sp = facts.get_variable("multiStore") ;
  if(Loci::MPI_processes > 1) {
    fact_db::distribute_infoP df = facts.get_distribute_info() ;
    remap = df->remap ;
    reorder_data = Loci::collect_reorder_store(new_sp, remap, facts) ;
  }
  hid_t  file_id, group_id;
  if(Loci::MPI_rank == 0) {
    file_id =  H5Fcreate("example", H5F_ACC_TRUNC,
                         H5P_DEFAULT, H5P_DEFAULT) ;
    group_id = H5Gcreate(file_id, "my_store", 0) ;
  }
  if(Loci::MPI_processes > 1)
    Loci::write_container(group_id, reorder_data) ;
  else
    Loci::write_container(group_id, data.Rep()) ;
  if(Loci::MPI_rank == 0) {
    H5Gclose(group_id) ;
    H5Fclose(file_id) ;
  }
  if(Loci::MPI_rank == 0) {
    file_id =  H5Fopen("example", H5F_ACC_RDONLY,
                       H5P_DEFAULT) ;
    group_id = H5Gopen(file_id, "my_store") ;
  }
  multiStore<Loci::My_Type> read_data ;
  entitySet tmp_Set ; 
  //if you dont know the domain to be read into you can pass an empty
  //domain as argument to read_container. 
  Loci::read_container(group_id, read_data.Rep(), tmp_set) ;
  // you can also read the data corresponding to a particular domain
  //by specifying the entitySet as an argument to the read routine.  
  Loci::debugout << "read_data = " << read_data << endl ;
  if(Loci::MPI_rank == 0) {
    H5Gclose(group_id) ;
    H5Fclose(file_id) ;
  }
  Loci::Finalize() ;
}
 
\end{verbatim} 

%
A single file gets written out no matter how many processors you use
to run the program. The file written out contains the framing
information denoted by {\tt first\_level} and {\tt second\_level}. The
{\tt first\_level} gives the number of objects for each entitity
whereas the {\tt second\_level} gives the sizes of the objects for each
entity. The {\t first\_level} and {\tt second\_level} is written out
only for multiStores with user defined objects otherwise only the
{\tt first\_level  is written out}. For the case of {\tt stores} and
{\tt storeVecs} there is no {\tt first\_level} as the {\tt vec\_size}
determines the number of objects per entity.     

\begin{verbatim}
HDF5 "example" {
GROUP "/" {
   GROUP "my_store" {
      DATASET "Interval Set" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 2 ) / ( 2 ) } 
         DATA {
            1, 10
         } 
      } 
      DATASET "first_level" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 10 ) / ( 10 ) } 
         DATA {
            1, 2, 3, 4, 5, 6, 7, 8, 9, 10
         } 
      } 
      DATASET "is_stat" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) } 
         DATA {
            1
         } 
      } 
      DATASET "data" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 225 ) / ( 225 ) } 
         DATA {
            1, 2, 3, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 1, 2, 3,
            4, 5, 6, 7, 8, 9, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
            111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 1, 2, 3, 4, 5, 6,
            7, 8, 9, 10, 11, 12, 13, 14, 15, 101, 102, 103, 104, 105, 106, 107,
            108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
            121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 1, 2, 3, 4, 5, 6,
            7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 101, 102,
            103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
            116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,
            129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 1, 2, 3,
            4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,
            22, 23, 24, 25, 26, 27, 101, 102, 103, 104, 105, 106, 107, 108, 109,
            110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,
            123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,
            136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
            149, 150
         } 
      } 
      DATASET "second_level" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 55 ) / ( 55 ) } 
         DATA {
            3, 5, 5, 3, 3, 3, 5, 5, 5, 5, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 3, 3,
            3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5,
            5, 5, 5, 5, 5, 5, 5, 5, 5
         } 
      } 
      DATASET "vec_size" {
         DATATYPE  H5T_STD_I32BE  
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) } 
         DATA {
            0
         } 
      } 
   } 
} 
} 
\end{verbatim} 
%
Users can also write out the containers by putting them into a local
fact database and write it out. They can so the same with respect to
reading also. The example below shows how a user can write out stores
without dealing with the details of Hdf5. 
%
\begin{verbatim}
#include <Loci.h>
using namespace std;

namespace Loci {
  struct My_Type {
    list<int>  alist;
    friend ostream& operator << (ostream &, const My_Type &);
    friend istream& operator >> (istream &, My_Type &);
  };
  
  //*******************************************************************
  inline std::ostream& operator << ( std::ostream &s, const My_Type &obj)
  {
    list<int> :: const_iterator ci;
    list<int> :: const_iterator begin = obj.alist.begin();
    list<int> :: const_iterator end   = obj.alist.end();
    for( ci = begin; ci != end; ++ci)
      s << *ci <<" ";
    return s;
  }
  //*******************************************************************
  inline std::istream& operator >> ( std::istream &s, My_Type &obj)
  {
    obj.alist.clear();
    int newval;
    s >> newval;
    obj.alist.push_back( newval );
    return s;
  }
  //*******************************************************************
  class My_Type_SchemaConverter;
  
  template <>
  struct data_schema_traits<My_Type> {
    typedef USER_DEFINED_CONVERTER Schema_Converter ;
    typedef int Converter_Base_Type ;
    typedef My_Type_SchemaConverter Converter_Type ;
  };
  
  class My_Type_SchemaConverter {
    // For the schema converter, we always store a reference to the object
    // we are converting schmata for.
    My_Type &RefObj ;
  public:
    explicit My_Type_SchemaConverter(My_Type &new_obj): RefObj(new_obj) {}
    int getSize() const {
      return RefObj.alist.size() ;
    }
    void getState(int *buf, int &size) {
      size = getSize() ;
      int ii=0;
      
      list<int> :: const_iterator ci;
      list<int> :: const_iterator begin = RefObj.alist.begin();
      list<int> :: const_iterator end   = RefObj.alist.end();
      for(ci = begin; ci != end; ++ci)  {
        buf[ii++] = *ci;
      }
    }
    void setState(int *buf, int size) {
      RefObj.alist.clear();
      for(int i=0;i<size;++i)
        RefObj.alist.push_back(buf[i]);
    }
  };
}
multiStore<Loci::My_Type> data ;   // Container
store<int> cnt ;
int num = 10 ;
entitySet eset  = interval(1, num) ;   // EntitySet
void GenerateData()
{
  cnt.allocate(eset) ;
  for(entitySet::const_iterator ei = eset.begin(); ei != eset.end(); ++ei)
    cnt[*ei] = *ei ;
  data.allocate(cnt) ;
  for(entitySet::const_iterator ei = eset.begin(); ei != eset.end(); ++ei) {
    int indx = 1;
    for(int i = 0; i < cnt[*ei]; ++i)
      for(int j = 0; j < 3; j++) {
        data[*ei][i].alist.push_back(indx);
        indx++;
      }
    indx = 1;
    ++ei ;
    for(int i = 0; i < cnt[*ei]; ++i)
      for(int j = 0; j < 5; j++) {
        data[*ei][i].alist.push_back(indx+100);
        indx++;
      }
  }
}

int main(int argc, char *argv[])
{ 
  Loci::Init(&argc, &argv) ;
  fact_db facts ;
  rule_db rdb ;
  dMap remap ;
  std::vector<entitySet> partition(Loci::MPI_processes) ;
  GenerateData() ;
  // create a fact for the multistore to write out. 
  facts.create_fact("multiStore", data) ; 
  // If you need to run the program on multiple processes you need to
  //include the following piece of code. 
  if(Loci::MPI_processes > 1) {
    // This is a generalized partitioning routine which uses the
    //serial metis partitioning. Not very scalable for large problems
    //The remap information as well as the chunked partitioning
    //information is stored for the scalable version. 
    
    partition = Loci::generate_scalable_distribution(facts, rdb, Loci::MPI_processes) ;
    
    //This routine assigns a local numbering to the entities inorder
    //to optimize scheduling and efficiency of computations. 
    Loci::distribute_facts(partition, facts, rdb) ;
    }
  facts.write_all_hdf5("example") ;
  multiStore<Loci::My_Type> read_data ;
  fact_db local_facts ;
  // create a fact to read in .
  // the allocation of the container happens in the reading process 
  local_facts.create_fact("multiStore", read_data) ;
  local_facts.read_all_hdf5("example") ;
  //chekout the debug files to see the read in data. 
  // Reading takes place according to the chunked partitioning. 
  //If you need to redistribute according to a given partition you
  //need to use read_all_hdf5 to read to a specific domain and then use 
  //distribute_reorder_store.
  Loci::debugout << "read_data = " << read_data << endl ;
  Loci::Finalize() ;
}
 
\end{verbatim}
    
